{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In case it is necessary to run in colaboratory\n",
    "# !python colab_module_imports.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from revllm.preprocess_distilbert import PreprocessQAndA\n",
    "from revllm.analyze_distilbert import AnalyzeQAndA \n",
    "from revllm.visualize_distilbert import VisualizeQAndA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question and Answer, or \"qanda\"\n",
    "* DistilBERT base model\n",
    "* fine-tuned on SQuAD, a standard question answering dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The user provides:\n",
    "\n",
    "* A question\n",
    "* A context, from which the model will extract the answer\n",
    "* A ground truth answer, which is what the model will try to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is important to us?\"\n",
    "context = \"It is important to us to include, empower and support humans of all kinds.\"\n",
    "ground_truth = \"to include, empower and support humans of all kinds\"\n",
    "\n",
    "# We use the same model as the huggingface baseline for qanda\n",
    "model = 'distilbert-base-uncased-distilled-squad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the objects\n",
    "preprocessor = PreprocessQAndA(model)\n",
    "analyzer = AnalyzeQAndA(model,preprocessor)\n",
    "visualizer = VisualizeQAndA(model,preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the question, context and ground truth to the preprocessor\n",
    "preprocessor(question, context, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .predict() method\n",
    "* Two predictions are made:\n",
    "    * A predicted start to the answer (token number)\n",
    "    * A predicted end to the answer (token number)\n",
    "* The predicted answer as shown is the text between the predicted start and end tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Question:  What is the name of the virus?\n",
      "Predicted Answer:  co ##vid - 19\n",
      "   Actual Answer:  COVID-19\n"
     ]
    }
   ],
   "source": [
    "# Run the model\n",
    "analyzer.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"lig\" methods\n",
    "* \"lig\" is a reference to the internal method used, \"layer integrated gradients\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .lig_color_map() method\n",
    "* Since the prediction consists of a start and end token, for each one here is shown:\n",
    "    * The predicted vs actual token\n",
    "    * The entire text is printed with question and context concatenated.  \n",
    "        * Above the text for each token, its importance to model's prediction (\"attribution score\") is shown in color.  \n",
    "        * A legend is included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.lig_color_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .lig_top_k_tokens() method\n",
    "* Prints the entire list of tokens\n",
    "* For each of the start and end token predictions, prints the top k attributed tokens, for a choice of k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.lig_top_k_tokens(k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"lc\" methods\n",
    "* \"lc\" is a reference to the internal method used, \"layer conductance\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .lc_visualize_layers() method\n",
    "* Creates 2 plots: one for the predicting start token, one for the predicting end token\n",
    "* For each token, a color tile representing the attribution score is given for each layer of the model (there are 6 layers in distilbert)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.lc_visualize_layers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .lc_visualize_token() method\n",
    "* For a choice of token (for example \"name\"), produces some plots.\n",
    "* This method is unfinished, an explanation to come."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_analyze = 'humans'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.lc_visualize_token_boxes(token_to_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.lc_visualize_token_pdfs(token_to_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.lc_visualize_token_entropies(token_to_analyze)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
