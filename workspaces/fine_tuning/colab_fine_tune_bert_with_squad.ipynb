{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d3Dtu1N9O38j"
      },
      "outputs": [],
      "source": [
        "# Adapted from https://huggingface.co/transformers/v3.2.0/custom_datasets.html#qa-squad\n",
        "\n",
        "# Training in the colab basic (free) notebook takes roughly 3.5 hours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3kMPhNZKwLc",
        "outputId": "619c79c0-6c33-47bc-bcb4-5af2c27d450e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.34.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.0.1+cu118)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.10->transformers[torch]) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.10->transformers[torch]) (17.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: bertviz in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: transformers>=2.0 in /usr/local/lib/python3.10/dist-packages (from bertviz) (4.34.0)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.10/dist-packages (from bertviz) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bertviz) (4.66.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from bertviz) (1.28.63)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bertviz) (2.31.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from bertviz) (2023.6.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bertviz) (0.1.99)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0->bertviz) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0->bertviz) (17.0.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (0.4.0)\n",
            "Requirement already satisfied: botocore<1.32.0,>=1.31.63 in /usr/local/lib/python3.10/dist-packages (from boto3->bertviz) (1.31.63)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->bertviz) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from boto3->bertviz) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.32.0,>=1.31.63->boto3->bertviz) (2.8.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers>=2.0->bertviz) (2023.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0->bertviz) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0->bertviz) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.63->boto3->bertviz) (1.16.0)\n",
            "Requirement already satisfied: captum in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from captum) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from captum) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->captum) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->captum) (17.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->captum) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->captum) (1.3.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (17.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.14.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.8.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3.post1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: torch-xla in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from torch-xla) (1.4.0)\n",
            "Requirement already satisfied: cloud-tpu-client>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from torch-xla) (0.10)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from torch-xla) (6.0.1)\n",
            "Requirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.10/dist-packages (from cloud-tpu-client>=0.10.0->torch-xla) (1.8.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from cloud-tpu-client>=0.10.0->torch-xla) (4.1.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla) (0.22.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla) (0.1.1)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla) (1.34.0)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla) (1.16.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla) (3.0.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch-xla) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch-xla) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch-xla) (4.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla) (1.60.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla) (5.3.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.9.2->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla) (3.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!python colab_module_imports.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-jPN5j5k_ze8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import DistilBertTokenizerFast\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AdamW\n",
        "from transformers import DistilBertForQuestionAnswering\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1drBxe1MLXRA",
        "outputId": "fabf0f26-fbd2-4bb7-d1b8-4736f528adf3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yGRRcO5CL_1t"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "453f942e452741c1adc9c43390334e9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/7.67k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset squad/plain_text to C:/Users/hello/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03042ad3710346ec98fda39d5d1ce35f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "ConnectionError",
          "evalue": "Couldn't reach https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json (ConnectionError(MaxRetryError(\"HTTPSConnectionPool(host='rajpurkar.github.io', port=443): Max retries exceeded with url: /SQuAD-explorer/dataset/train-v1.1.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002149C5A3E10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\")))",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\hello\\Desktop\\llm_bootcamp\\revllm_repo\\workspaces\\fine_tuning\\colab_fine_tune_bert_with_squad.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hello/Desktop/llm_bootcamp/revllm_repo/workspaces/fine_tuning/colab_fine_tune_bert_with_squad.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dataset \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39m\u001b[39msquad\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hello/Desktop/llm_bootcamp/revllm_repo/workspaces/fine_tuning/colab_fine_tune_bert_with_squad.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_contexts \u001b[39m=\u001b[39m dataset[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hello/Desktop/llm_bootcamp/revllm_repo/workspaces/fine_tuning/colab_fine_tune_bert_with_squad.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train_questions \u001b[39m=\u001b[39m dataset[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m\"\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\hello\\anaconda3\\Lib\\site-packages\\datasets\\load.py:1797\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[0;32m   1794\u001b[0m try_from_hf_gcs \u001b[39m=\u001b[39m path \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m _PACKAGED_DATASETS_MODULES\n\u001b[0;32m   1796\u001b[0m \u001b[39m# Download and prepare data\u001b[39;00m\n\u001b[1;32m-> 1797\u001b[0m builder_instance\u001b[39m.\u001b[39mdownload_and_prepare(\n\u001b[0;32m   1798\u001b[0m     download_config\u001b[39m=\u001b[39mdownload_config,\n\u001b[0;32m   1799\u001b[0m     download_mode\u001b[39m=\u001b[39mdownload_mode,\n\u001b[0;32m   1800\u001b[0m     verification_mode\u001b[39m=\u001b[39mverification_mode,\n\u001b[0;32m   1801\u001b[0m     try_from_hf_gcs\u001b[39m=\u001b[39mtry_from_hf_gcs,\n\u001b[0;32m   1802\u001b[0m     num_proc\u001b[39m=\u001b[39mnum_proc,\n\u001b[0;32m   1803\u001b[0m     storage_options\u001b[39m=\u001b[39mstorage_options,\n\u001b[0;32m   1804\u001b[0m )\n\u001b[0;32m   1806\u001b[0m \u001b[39m# Build dataset for splits\u001b[39;00m\n\u001b[0;32m   1807\u001b[0m keep_in_memory \u001b[39m=\u001b[39m (\n\u001b[0;32m   1808\u001b[0m     keep_in_memory \u001b[39mif\u001b[39;00m keep_in_memory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m is_small_dataset(builder_instance\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size)\n\u001b[0;32m   1809\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\hello\\anaconda3\\Lib\\site-packages\\datasets\\builder.py:890\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[1;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[0;32m    888\u001b[0m     \u001b[39mif\u001b[39;00m num_proc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    889\u001b[0m         prepare_split_kwargs[\u001b[39m\"\u001b[39m\u001b[39mnum_proc\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m num_proc\n\u001b[1;32m--> 890\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download_and_prepare(\n\u001b[0;32m    891\u001b[0m         dl_manager\u001b[39m=\u001b[39mdl_manager,\n\u001b[0;32m    892\u001b[0m         verification_mode\u001b[39m=\u001b[39mverification_mode,\n\u001b[0;32m    893\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mprepare_split_kwargs,\n\u001b[0;32m    894\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdownload_and_prepare_kwargs,\n\u001b[0;32m    895\u001b[0m     )\n\u001b[0;32m    896\u001b[0m \u001b[39m# Sync info\u001b[39;00m\n\u001b[0;32m    897\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(split\u001b[39m.\u001b[39mnum_bytes \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39msplits\u001b[39m.\u001b[39mvalues())\n",
            "File \u001b[1;32mc:\\Users\\hello\\anaconda3\\Lib\\site-packages\\datasets\\builder.py:1649\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, verification_mode, **prepare_splits_kwargs)\u001b[0m\n\u001b[0;32m   1648\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_download_and_prepare\u001b[39m(\u001b[39mself\u001b[39m, dl_manager, verification_mode, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mprepare_splits_kwargs):\n\u001b[1;32m-> 1649\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_download_and_prepare(\n\u001b[0;32m   1650\u001b[0m         dl_manager,\n\u001b[0;32m   1651\u001b[0m         verification_mode,\n\u001b[0;32m   1652\u001b[0m         check_duplicate_keys\u001b[39m=\u001b[39mverification_mode \u001b[39m==\u001b[39m VerificationMode\u001b[39m.\u001b[39mBASIC_CHECKS\n\u001b[0;32m   1653\u001b[0m         \u001b[39mor\u001b[39;00m verification_mode \u001b[39m==\u001b[39m VerificationMode\u001b[39m.\u001b[39mALL_CHECKS,\n\u001b[0;32m   1654\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mprepare_splits_kwargs,\n\u001b[0;32m   1655\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\hello\\anaconda3\\Lib\\site-packages\\datasets\\builder.py:963\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m split_dict \u001b[39m=\u001b[39m SplitDict(dataset_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[0;32m    962\u001b[0m split_generators_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_split_generators_kwargs(prepare_split_kwargs)\n\u001b[1;32m--> 963\u001b[0m split_generators \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split_generators(dl_manager, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msplit_generators_kwargs)\n\u001b[0;32m    965\u001b[0m \u001b[39m# Checksums verification\u001b[39;00m\n\u001b[0;32m    966\u001b[0m \u001b[39mif\u001b[39;00m verification_mode \u001b[39m==\u001b[39m VerificationMode\u001b[39m.\u001b[39mALL_CHECKS \u001b[39mand\u001b[39;00m dl_manager\u001b[39m.\u001b[39mrecord_checksums:\n",
            "File \u001b[1;32m~\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\squad\\d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453\\squad.py:110\u001b[0m, in \u001b[0;36mSquad._split_generators\u001b[1;34m(self, dl_manager)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_split_generators\u001b[39m(\u001b[39mself\u001b[39m, dl_manager):\n\u001b[1;32m--> 110\u001b[0m     downloaded_files \u001b[39m=\u001b[39m dl_manager\u001b[39m.\u001b[39mdownload_and_extract(_URLS)\n\u001b[0;32m    112\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m    113\u001b[0m         datasets\u001b[39m.\u001b[39mSplitGenerator(name\u001b[39m=\u001b[39mdatasets\u001b[39m.\u001b[39mSplit\u001b[39m.\u001b[39mTRAIN, gen_kwargs\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mfilepath\u001b[39m\u001b[39m\"\u001b[39m: downloaded_files[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m]}),\n\u001b[0;32m    114\u001b[0m         datasets\u001b[39m.\u001b[39mSplitGenerator(name\u001b[39m=\u001b[39mdatasets\u001b[39m.\u001b[39mSplit\u001b[39m.\u001b[39mVALIDATION, gen_kwargs\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mfilepath\u001b[39m\u001b[39m\"\u001b[39m: downloaded_files[\u001b[39m\"\u001b[39m\u001b[39mdev\u001b[39m\u001b[39m\"\u001b[39m]}),\n\u001b[0;32m    115\u001b[0m     ]\n",
            "File \u001b[1;32mc:\\Users\\hello\\anaconda3\\Lib\\site-packages\\datasets\\download\\download_manager.py:564\u001b[0m, in \u001b[0;36mDownloadManager.download_and_extract\u001b[1;34m(self, url_or_urls)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdownload_and_extract\u001b[39m(\u001b[39mself\u001b[39m, url_or_urls):\n\u001b[0;32m    549\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Download and extract given `url_or_urls`.\u001b[39;00m\n\u001b[0;32m    550\u001b[0m \n\u001b[0;32m    551\u001b[0m \u001b[39m    Is roughly equivalent to:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[39m        extracted_path(s): `str`, extracted paths of given URL(s).\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 564\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownload(url_or_urls))\n",
            "File \u001b[1;32mc:\\Users\\hello\\anaconda3\\Lib\\site-packages\\datasets\\download\\download_manager.py:427\u001b[0m, in \u001b[0;36mDownloadManager.download\u001b[1;34m(self, url_or_urls)\u001b[0m\n\u001b[0;32m    424\u001b[0m download_func \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download, download_config\u001b[39m=\u001b[39mdownload_config)\n\u001b[0;32m    426\u001b[0m start_time \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\n\u001b[1;32m--> 427\u001b[0m downloaded_path_or_paths \u001b[39m=\u001b[39m map_nested(\n\u001b[0;32m    428\u001b[0m     download_func,\n\u001b[0;32m    429\u001b[0m     url_or_urls,\n\u001b[0;32m    430\u001b[0m     map_tuple\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    431\u001b[0m     num_proc\u001b[39m=\u001b[39mdownload_config\u001b[39m.\u001b[39mnum_proc,\n\u001b[0;32m    432\u001b[0m     disable_tqdm\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m is_progress_bar_enabled(),\n\u001b[0;32m    433\u001b[0m     desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading data files\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    434\u001b[0m )\n\u001b[0;32m    435\u001b[0m duration \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow() \u001b[39m-\u001b[39m start_time\n\u001b[0;32m    436\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading took \u001b[39m\u001b[39m{\u001b[39;00mduration\u001b[39m.\u001b[39mtotal_seconds()\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39m\u001b[39m60\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m min\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\hello\\anaconda3\\Lib\\site-packages\\datasets\\utils\\py_utils.py:443\u001b[0m, in \u001b[0;36mmap_nested\u001b[1;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, types, disable_tqdm, desc)\u001b[0m\n\u001b[0;32m    441\u001b[0m     num_proc \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    442\u001b[0m \u001b[39mif\u001b[39;00m num_proc \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(iterable) \u001b[39m<\u001b[39m parallel_min_length:\n\u001b[1;32m--> 443\u001b[0m     mapped \u001b[39m=\u001b[39m [\n\u001b[0;32m    444\u001b[0m         _single_map_nested((function, obj, types, \u001b[39mNone\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    445\u001b[0m         \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(iterable, disable\u001b[39m=\u001b[39mdisable_tqdm, desc\u001b[39m=\u001b[39mdesc)\n\u001b[0;32m    446\u001b[0m     ]\n\u001b[0;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    448\u001b[0m     num_proc \u001b[39m=\u001b[39m num_proc \u001b[39mif\u001b[39;00m num_proc \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(iterable) \u001b[39melse\u001b[39;00m \u001b[39mlen\u001b[39m(iterable)\n",
            "File \u001b[1;32mc:\\Users\\hello\\anaconda3\\Lib\\site-packages\\datasets\\utils\\py_utils.py:444\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    441\u001b[0m     num_proc \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    442\u001b[0m \u001b[39mif\u001b[39;00m num_proc \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(iterable) \u001b[39m<\u001b[39m parallel_min_length:\n\u001b[0;32m    443\u001b[0m     mapped \u001b[39m=\u001b[39m [\n\u001b[1;32m--> 444\u001b[0m         _single_map_nested((function, obj, types, \u001b[39mNone\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    445\u001b[0m         \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(iterable, disable\u001b[39m=\u001b[39mdisable_tqdm, desc\u001b[39m=\u001b[39mdesc)\n\u001b[0;32m    446\u001b[0m     ]\n\u001b[0;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    448\u001b[0m     num_proc \u001b[39m=\u001b[39m num_proc \u001b[39mif\u001b[39;00m num_proc \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(iterable) \u001b[39melse\u001b[39;00m \u001b[39mlen\u001b[39m(iterable)\n",
            "File \u001b[1;32mc:\\Users\\hello\\anaconda3\\Lib\\site-packages\\datasets\\utils\\py_utils.py:346\u001b[0m, in \u001b[0;36m_single_map_nested\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[39m# Singleton first to spare some computation\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, \u001b[39mdict\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, types):\n\u001b[1;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m function(data_struct)\n\u001b[0;32m    348\u001b[0m \u001b[39m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \u001b[39mif\u001b[39;00m rank \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m logging\u001b[39m.\u001b[39mget_verbosity() \u001b[39m<\u001b[39m logging\u001b[39m.\u001b[39mWARNING:\n",
            "File \u001b[1;32mc:\\Users\\hello\\anaconda3\\Lib\\site-packages\\datasets\\download\\download_manager.py:453\u001b[0m, in \u001b[0;36mDownloadManager._download\u001b[1;34m(self, url_or_filename, download_config)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[39mif\u001b[39;00m is_relative_path(url_or_filename):\n\u001b[0;32m    451\u001b[0m     \u001b[39m# append the relative path to the base_path\u001b[39;00m\n\u001b[0;32m    452\u001b[0m     url_or_filename \u001b[39m=\u001b[39m url_or_path_join(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_base_path, url_or_filename)\n\u001b[1;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m cached_path(url_or_filename, download_config\u001b[39m=\u001b[39mdownload_config)\n",
            "File \u001b[1;32mc:\\Users\\hello\\anaconda3\\Lib\\site-packages\\datasets\\utils\\file_utils.py:183\u001b[0m, in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m     url_or_filename \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(url_or_filename)\n\u001b[0;32m    181\u001b[0m \u001b[39mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[0;32m    182\u001b[0m     \u001b[39m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[1;32m--> 183\u001b[0m     output_path \u001b[39m=\u001b[39m get_from_cache(\n\u001b[0;32m    184\u001b[0m         url_or_filename,\n\u001b[0;32m    185\u001b[0m         cache_dir\u001b[39m=\u001b[39mcache_dir,\n\u001b[0;32m    186\u001b[0m         force_download\u001b[39m=\u001b[39mdownload_config\u001b[39m.\u001b[39mforce_download,\n\u001b[0;32m    187\u001b[0m         proxies\u001b[39m=\u001b[39mdownload_config\u001b[39m.\u001b[39mproxies,\n\u001b[0;32m    188\u001b[0m         resume_download\u001b[39m=\u001b[39mdownload_config\u001b[39m.\u001b[39mresume_download,\n\u001b[0;32m    189\u001b[0m         user_agent\u001b[39m=\u001b[39mdownload_config\u001b[39m.\u001b[39muser_agent,\n\u001b[0;32m    190\u001b[0m         local_files_only\u001b[39m=\u001b[39mdownload_config\u001b[39m.\u001b[39mlocal_files_only,\n\u001b[0;32m    191\u001b[0m         use_etag\u001b[39m=\u001b[39mdownload_config\u001b[39m.\u001b[39muse_etag,\n\u001b[0;32m    192\u001b[0m         max_retries\u001b[39m=\u001b[39mdownload_config\u001b[39m.\u001b[39mmax_retries,\n\u001b[0;32m    193\u001b[0m         use_auth_token\u001b[39m=\u001b[39mdownload_config\u001b[39m.\u001b[39muse_auth_token,\n\u001b[0;32m    194\u001b[0m         ignore_url_params\u001b[39m=\u001b[39mdownload_config\u001b[39m.\u001b[39mignore_url_params,\n\u001b[0;32m    195\u001b[0m         storage_options\u001b[39m=\u001b[39mdownload_config\u001b[39m.\u001b[39mstorage_options,\n\u001b[0;32m    196\u001b[0m         download_desc\u001b[39m=\u001b[39mdownload_config\u001b[39m.\u001b[39mdownload_desc,\n\u001b[0;32m    197\u001b[0m     )\n\u001b[0;32m    198\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(url_or_filename):\n\u001b[0;32m    199\u001b[0m     \u001b[39m# File, and it exists.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m     output_path \u001b[39m=\u001b[39m url_or_filename\n",
            "File \u001b[1;32mc:\\Users\\hello\\anaconda3\\Lib\\site-packages\\datasets\\utils\\file_utils.py:566\u001b[0m, in \u001b[0;36mget_from_cache\u001b[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only, use_etag, max_retries, use_auth_token, ignore_url_params, storage_options, download_desc)\u001b[0m\n\u001b[0;32m    564\u001b[0m _raise_if_offline_mode_is_enabled(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTried to reach \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    565\u001b[0m \u001b[39mif\u001b[39;00m head_error \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 566\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt reach \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(head_error)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    567\u001b[0m \u001b[39melif\u001b[39;00m response \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    568\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt reach \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m (error \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;31mConnectionError\u001b[0m: Couldn't reach https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json (ConnectionError(MaxRetryError(\"HTTPSConnectionPool(host='rajpurkar.github.io', port=443): Max retries exceeded with url: /SQuAD-explorer/dataset/train-v1.1.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002149C5A3E10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\")))"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(\"squad\")\n",
        "\n",
        "train_contexts = dataset[\"train\"][\"context\"]\n",
        "train_questions = dataset[\"train\"][\"question\"]\n",
        "train_answers = dataset[\"train\"][\"answers\"]\n",
        "\n",
        "val_contexts = dataset[\"validation\"][\"context\"]\n",
        "val_questions = dataset[\"validation\"][\"question\"]\n",
        "val_answers = dataset[\"validation\"][\"answers\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OZzoIfU18U6i"
      },
      "outputs": [],
      "source": [
        "# dataset_2 = load_dataset(\"squad_v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsD5miM7MvKW",
        "outputId": "430d5abb-dd0e-4249-9737-7ea9c21af5f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 87599\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 10570\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0shNVf3MwCL",
        "outputId": "f1108aee-6290-4277-b00f-e5f57444b150"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Panthers finished the regular season with a 15–1 record, and quarterback Cam Newton was named the NFL Most Valuable Player (MVP). They defeated the Arizona Cardinals 49–15 in the NFC Championship Game and advanced to their second Super Bowl appearance since the franchise was founded in 1995. The Broncos finished the regular season with a 12–4 record, and denied the New England Patriots a chance to defend their title from Super Bowl XLIX by defeating them 20–18 in the AFC Championship Game. They joined the Patriots, Dallas Cowboys, and Pittsburgh Steelers as one of four teams that have made eight appearances in the Super Bowl.\n",
            "Who did the Broncos prevent from going to the Super Bowl?\n",
            "{'text': ['New England Patriots', 'the New England Patriots', 'New England Patriots'], 'answer_start': [372, 368, 372]}\n"
          ]
        }
      ],
      "source": [
        "num = 34\n",
        "# print(train_contexts[num])\n",
        "# print(train_questions[num])\n",
        "# print(train_answers[num])\n",
        "\n",
        "print(val_contexts[num])\n",
        "print(val_questions[num])\n",
        "print(val_answers[num])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-QeVeZKTqH3"
      },
      "source": [
        "# My data set has a different format.  Namely, I have a list for 'text' in the answers.  This creates an issue in the val_answers since the length > 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TgMfPUZ_OTZ-"
      },
      "outputs": [],
      "source": [
        "def add_end_idx(answers, contexts):\n",
        "    for answer, context in zip(answers, contexts):\n",
        "\n",
        "        #Note: for this experiment, I am only taking the first element of a list.\n",
        "        #The difference is in the val_answers, which have lists longer than 1.\n",
        "        #So my experiment will not be on the full data.\n",
        "        answer['text'] = answer['text'][0]\n",
        "        answer['answer_start'] = answer['answer_start'][0]\n",
        "\n",
        "        gold_text = answer['text']\n",
        "        start_idx = answer['answer_start']\n",
        "        end_idx = start_idx + len(gold_text)\n",
        "\n",
        "        # sometimes squad answers are off by a character or two – fix this\n",
        "        if context[start_idx:end_idx] == gold_text:\n",
        "            answer['answer_end'] = end_idx\n",
        "        elif context[start_idx-1:end_idx-1] == gold_text:\n",
        "            answer['answer_start'] = start_idx - 1\n",
        "            answer['answer_end'] = end_idx - 1     # When the gold label is off by one character\n",
        "        elif context[start_idx-2:end_idx-2] == gold_text:\n",
        "            answer['answer_start'] = start_idx - 2\n",
        "            answer['answer_end'] = end_idx - 2     # When the gold label is off by two characters\n",
        "\n",
        "add_end_idx(train_answers, train_contexts)\n",
        "add_end_idx(val_answers, val_contexts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7aQBj5ZjoYs",
        "outputId": "e5b41066-7716-4df5-eb1e-1f828ac882e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In 1882, Albert Zahm (John Zahm's brother) built an early wind tunnel used to compare lift to drag of aeronautical models. Around 1899, Professor Jerome Green became the first American to send a wireless message. In 1931, Father Julius Nieuwland performed early work on basic reactions that was used to create neoprene. Study of nuclear physics at the university began with the building of a nuclear accelerator in 1936, and continues now partly through a partnership in the Joint Institute for Nuclear Astrophysics.\n",
            "Which professor sent the first wireless message in the USA?\n",
            "{'text': 'Professor Jerome Green', 'answer_start': 136, 'answer_end': 158}\n",
            "The Broncos took an early lead in Super Bowl 50 and never trailed. Newton was limited by Denver's defense, which sacked him seven times and forced him into three turnovers, including a fumble which they recovered for a touchdown. Denver linebacker Von Miller was named Super Bowl MVP, recording five solo tackles, 2½ sacks, and two forced fumbles.\n",
            "Who was the Super Bowl 50 MVP?\n",
            "{'text': 'Von Miller', 'answer_start': 248, 'answer_end': 258}\n"
          ]
        }
      ],
      "source": [
        "num = 55\n",
        "\n",
        "print(train_contexts[num])\n",
        "print(train_questions[num])\n",
        "print(train_answers[num])\n",
        "\n",
        "print(val_contexts[num])\n",
        "print(val_questions[num])\n",
        "print(val_answers[num])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SzjkOExjldxi"
      },
      "outputs": [],
      "source": [
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "T8aOaYWvljlL"
      },
      "outputs": [],
      "source": [
        "def add_token_positions(encodings, answers):\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "    for i in range(len(answers)):\n",
        "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
        "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n",
        "        # if None, the answer passage has been truncated\n",
        "        if start_positions[-1] is None:\n",
        "            start_positions[-1] = tokenizer.model_max_length\n",
        "        if end_positions[-1] is None:\n",
        "            end_positions[-1] = tokenizer.model_max_length\n",
        "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "\n",
        "add_token_positions(train_encodings, train_answers)\n",
        "add_token_positions(val_encodings, val_answers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UlpS1lX9cCf",
        "outputId": "08b80fa8-2770-43dc-bd71-a1e1c6df68ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "At age eight, Beyoncé and childhood friend Kelly Rowland met LaTavia Roberson while in an audition for an all-girl entertainment group. They were placed into a group with three other girls as Girl's Tyme, and rapped and danced on the talent show circuit in Houston. After seeing the group, R&B producer Arne Frager brought them to his Northern California studio and placed them in Star Search, the largest talent show on national TV at the time. Girl's Tyme failed to win, and Beyoncé later said the song they performed was not good. In 1995 Beyoncé's father resigned from his job to manage the group. The move reduced Beyoncé's family's income by half, and her parents were forced to move into separated apartments. Mathew cut the original line-up to four and the group continued performing as an opening act for other established R&B girl groups. The girls auditioned before record labels and were finally signed to Elektra Records, moving to Atlanta Records briefly to work on their first recording, only to be cut by the company. This put further strain on the family, and Beyoncé's parents separated. On October 5, 1995, Dwayne Wiggins's Grass Roots Entertainment signed the group. In 1996, the girls began recording their debut album under an agreement with Sony Music, the Knowles family reunited, and shortly after, the group got a contract with Columbia Records.\n",
            "How old was Beyoncé when she met LaTavia Roberson?\n",
            "{'text': 'eight', 'answer_start': 7, 'answer_end': 12}\n",
            "Carolina suffered a major setback when Thomas Davis, an 11-year veteran who had already overcome three ACL tears in his career, went down with a broken arm in the NFC Championship Game. Despite this, he insisted he would still find a way to play in the Super Bowl. His prediction turned out to be accurate.\n",
            "Who suffered a broken arm in the NFC Championship Game?\n",
            "{'text': 'Thomas Davis', 'answer_start': 39, 'answer_end': 51}\n"
          ]
        }
      ],
      "source": [
        "num = 345\n",
        "\n",
        "print(train_contexts[num])\n",
        "print(train_questions[num])\n",
        "print(train_answers[num])\n",
        "\n",
        "print(val_contexts[num])\n",
        "print(val_questions[num])\n",
        "print(val_answers[num])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JPjOe2GjllQm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class SquadDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "train_dataset = SquadDataset(train_encodings)\n",
        "val_dataset = SquadDataset(val_encodings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bFOuC9WmayQ",
        "outputId": "bd42dafb-5375-4568-a34b-755b9f2789f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db48GzSRmgHQ",
        "outputId": "0fa92f1c-e754-4da7-d430-5723cec3637c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DistilBertForQuestionAnswering(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "model.to(device)\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "zrxC34vzh_g6"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAO7IkWdiaQt"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "# train_loader_list = list(train_loader)\n",
        "train_loader_len = len(list(train_loader))\n",
        "\n",
        "optim = AdamW(model.parameters(), lr=5e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOX3Pko3nvCU",
        "outputId": "584f1637-87e8-43dd-a1de-d8d951ea3d90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 is 99.98173515981735 % done.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DistilBertForQuestionAnswering(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for epoch in range(3):\n",
        "\n",
        "  # So I can see the running status\n",
        "  print(epoch)\n",
        "  counter = 0\n",
        "  for batch in train_loader:\n",
        "\n",
        "    # So I can see the running status\n",
        "    # batch_index = train_loader_list.index(batch)\n",
        "    clear_output(wait=True)\n",
        "    print(f\"Epoch {epoch} is {100*counter/train_loader_len} % done.\" )\n",
        "    counter +=1\n",
        "\n",
        "    optim.zero_grad()\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    start_positions = batch['start_positions'].to(device)\n",
        "    end_positions = batch['end_positions'].to(device)\n",
        "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
        "    loss = outputs[0]\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kp1C3E5_EK7G",
        "outputId": "7540b3cf-06b1-44cf-d758-b4ce3e56baad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./bert_tuned_on_squad/tokenizer_config.json',\n",
              " './bert_tuned_on_squad/special_tokens_map.json',\n",
              " './bert_tuned_on_squad/vocab.txt',\n",
              " './bert_tuned_on_squad/added_tokens.json',\n",
              " './bert_tuned_on_squad/tokenizer.json')"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "save_directory = './bert_tuned_on_squad'\n",
        "\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBbMFoLL7WNi"
      },
      "outputs": [],
      "source": [
        "#Currently using colab, so to download\n",
        "from google.colab import files\n",
        "\n",
        "# Download tokenizer files\n",
        "files.download('./bert_tuned_on_squad/tokenizer_config.json')\n",
        "files.download('./bert_tuned_on_squad/special_tokens_map.json')\n",
        "files.download('./bert_tuned_on_squad/vocab.txt')\n",
        "files.download('./bert_tuned_on_squad/added_tokens.json')\n",
        "files.download('./bert_tuned_on_squad/tokenizer.json')\n",
        "\n",
        "# Download model files\n",
        "files.download('./bert_tuned_on_squad/config.json')\n",
        "files.download('./bert_tuned_on_squad/pytorch_model.bin')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
