{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DistilBertForZeroShotClassification' from 'transformers' (c:\\Users\\hello\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hello\\Desktop\\llm_bootcamp\\revllm_repo\\workspaces\\editing_workspace.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hello/Desktop/llm_bootcamp/revllm_repo/workspaces/editing_workspace.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m DistilBertForZeroShotClassification\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'DistilBertForZeroShotClassification' from 'transformers' (c:\\Users\\hello\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForZeroShotClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lig_color_map(predict, ):\n",
    "\n",
    "    lig = LayerIntegratedGradients(predict, self.model.distilbert.embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lig_color_map_qanda(self):\n",
    "\n",
    "    lig = LayerIntegratedGradients(self.predict, self.model.distilbert.embeddings)\n",
    "\n",
    "    attributions_start, delta_start = lig.attribute(inputs=self.preprocessor.input_ids,\n",
    "                                                    baselines=self.preprocessor.baseline_input_ids,\n",
    "                                                    additional_forward_args=(self.preprocessor.attention_mask,0,False),\n",
    "                                                    return_convergence_delta=True)\n",
    "    attributions_end, delta_end = lig.attribute(inputs=self.preprocessor.input_ids, \n",
    "                                                baselines=self.preprocessor.baseline_input_ids,\n",
    "                                                additional_forward_args=(self.preprocessor.attention_mask,1,False),\n",
    "                                                return_convergence_delta=True)\n",
    "\n",
    "    attributions_start_sum = summarize_attributions(attributions_start)\n",
    "    attributions_end_sum = summarize_attributions(attributions_end)\n",
    "\n",
    "    # storing couple samples in an array for visualization purposes\n",
    "    start_position_vis = viz.VisualizationDataRecord(\n",
    "                            attributions_start_sum,\n",
    "                            torch.max(torch.softmax(self.start_scores[0], dim=0)),\n",
    "                            torch.argmax(self.start_scores),\n",
    "                            torch.argmax(self.start_scores),\n",
    "                            str(self.preprocessor.ground_truth_start_ind),\n",
    "                            attributions_start_sum.sum(),       \n",
    "                            self.preprocessor.all_tokens,\n",
    "                            delta_start)\n",
    "\n",
    "    end_position_vis = viz.VisualizationDataRecord(\n",
    "                            attributions_end_sum,\n",
    "                            torch.max(torch.softmax(self.end_scores[0], dim=0)),\n",
    "                            torch.argmax(self.end_scores),\n",
    "                            torch.argmax(self.end_scores),\n",
    "                            str(self.preprocessor.ground_truth_end_ind),\n",
    "                            attributions_end_sum.sum(),       \n",
    "                            self.preprocessor.all_tokens,\n",
    "                            delta_end)\n",
    "\n",
    "    print('\\033[1m', 'Visualizations For Start Position', '\\033[0m')\n",
    "    viz.visualize_text([start_position_vis])\n",
    "\n",
    "    print('\\033[1m', 'Visualizations For End Position', '\\033[0m')\n",
    "    viz.visualize_text([end_position_vis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lig_color_map_sentiment(self):\n",
    "    \n",
    "    lig = LayerIntegratedGradients(self.predict, self.model.distilbert.embeddings)\n",
    "    \n",
    "    # Get attributions for the sentiment prediction\n",
    "    attributions, delta = lig.attribute(inputs=self.preprocessor.input_ids,\n",
    "                                        baselines=self.preprocessor.baseline_input_ids,\n",
    "                                        additional_forward_args=(self.preprocessor.attention_mask, False),\n",
    "                                        return_convergence_delta=True,\n",
    "                                        target=self.preprocessor.ground_truth_index)\n",
    "    \n",
    "    attributions_sum = summarize_attributions(attributions)\n",
    "    \n",
    "    # Use the stored logits\n",
    "    sentiment_score = torch.softmax(self.logits[0], dim=0)\n",
    "    predicted_class = torch.argmax(sentiment_score)\n",
    "    \n",
    "    sentiment_vis = viz.VisualizationDataRecord(\n",
    "                        attributions_sum,\n",
    "                        torch.max(sentiment_score),\n",
    "                        predicted_class,\n",
    "                        predicted_class,\n",
    "                        str(self.preprocessor.ground_truth_index),\n",
    "                        attributions_sum.sum(),       \n",
    "                        self.preprocessor.all_tokens,\n",
    "                        delta)\n",
    "\n",
    "    print('\\033[1m', 'Visualizations For Sentiment Prediction', '\\033[0m')\n",
    "    viz.visualize_text([sentiment_vis])\n",
    "  \n",
    "  def lig_top_k_tokens(self, k:int=5) -> None:\n",
    "    lig = LayerIntegratedGradients(self.predict, [self.model.distilbert.embeddings.word_embeddings])\n",
    "\n",
    "    attributions = lig.attribute(inputs=self.preprocessor.input_ids,\n",
    "                                 baselines=self.preprocessor.baseline_input_ids,\n",
    "                                 additional_forward_args=(self.preprocessor.attention_mask,False),\n",
    "                                 target=self.preprocessor.ground_truth_index)\n",
    "\n",
    "    attributions_word = summarize_attributions(attributions[0])\n",
    "    top_words, top_words_val, top_word_ind = get_top_k_attributed_tokens(attributions_word, k=k, preprocessor=self.preprocessor)\n",
    "\n",
    "    df = pd.DataFrame({'Word(Index), Attribution': [\"{} ({}), {}\".format(word, pos, round(val.item(),2)) for word, pos, val in zip(top_words, top_word_ind, top_words_val)]})\n",
    "    df.style.set_properties(cell_ids=False)\n",
    "\n",
    "    full_token_list = ['{}({})'.format(token, str(i)) for i, token in enumerate(self.preprocessor.all_tokens)]\n",
    "\n",
    "    print(f\"Full token list: {full_token_list}\")\n",
    "    print(f\"Top {k} attributed embeddings for sentiment prediction: {df}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
