{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To run now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Analyzer import DistilBertQandAAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_analyzer = DistilBertQandAAnalyzer('distilbert-base-uncased-distilled-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Question:  What is the name of the virus?\n",
      "Predicted Answer:  co ##vid - 19\n",
      "   Actual Answer:  COVID-19\n"
     ]
    }
   ],
   "source": [
    "squad_analyzer(\"What is the name of the virus?\", \"The name of the virus is COVID-19.\", \"COVID-19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "squad_analyzer.visualize_layers(token_to_explain=2) #To pick a random number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "squad_analyzer.top_5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "squad_analyzer.visualize_start_end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Future Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# base_analyzer = DistilBertQandAAnalyzer('distilbert-base-uncased')\n",
    "# squad_analyzer = DistilBertQandAAnalyzer('distilbert-base-uncased-distilled-squad')\n",
    "# squad2_analyzer = DistilBertQandAAnalyzer('twmkn9/distilbert-base-uncased-squad2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerIntegratedGradients, LayerConductance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function attribute in module captum.attr._core.layer.layer_integrated_gradients:\n",
      "\n",
      "attribute(self, inputs: Union[torch.Tensor, Tuple[torch.Tensor, ...]], baselines: Union[NoneType, torch.Tensor, int, float, Tuple[Union[torch.Tensor, int, float], ...]] = None, target: Union[NoneType, int, Tuple[int, ...], torch.Tensor, List[Tuple[int, ...]], List[int]] = None, additional_forward_args: Any = None, n_steps: int = 50, method: str = 'gausslegendre', internal_batch_size: Optional[int] = None, return_convergence_delta: bool = False, attribute_to_layer_input: bool = False) -> Union[torch.Tensor, Tuple[torch.Tensor, ...], List[Union[torch.Tensor, Tuple[torch.Tensor, ...]]], Tuple[Union[torch.Tensor, Tuple[torch.Tensor, ...], List[Union[torch.Tensor, Tuple[torch.Tensor, ...]]]], torch.Tensor]]\n",
      "    This method attributes the output of the model with given target index\n",
      "    (in case it is provided, otherwise it assumes that output is a\n",
      "    scalar) to layer inputs or outputs of the model, depending on whether\n",
      "    `attribute_to_layer_input` is set to True or False, using the approach\n",
      "    described above.\n",
      "    \n",
      "    In addition to that it also returns, if `return_convergence_delta` is\n",
      "    set to True, integral approximation delta based on the completeness\n",
      "    property of integrated gradients.\n",
      "    \n",
      "    Args:\n",
      "    \n",
      "        inputs (Tensor or tuple[Tensor, ...]): Input for which layer integrated\n",
      "                    gradients are computed. If forward_func takes a single\n",
      "                    tensor as input, a single input tensor should be provided.\n",
      "                    If forward_func takes multiple tensors as input, a tuple\n",
      "                    of the input tensors should be provided. It is assumed\n",
      "                    that for all given input tensors, dimension 0 corresponds\n",
      "                    to the number of examples, and if multiple input tensors\n",
      "                    are provided, the examples must be aligned appropriately.\n",
      "        baselines (scalar, Tensor, tuple of scalar, or Tensor, optional):\n",
      "                    Baselines define the starting point from which integral\n",
      "                    is computed and can be provided as:\n",
      "    \n",
      "                    - a single tensor, if inputs is a single tensor, with\n",
      "                      exactly the same dimensions as inputs or the first\n",
      "                      dimension is one and the remaining dimensions match\n",
      "                      with inputs.\n",
      "    \n",
      "                    - a single scalar, if inputs is a single tensor, which will\n",
      "                      be broadcasted for each input value in input tensor.\n",
      "    \n",
      "                    - a tuple of tensors or scalars, the baseline corresponding\n",
      "                      to each tensor in the inputs' tuple can be:\n",
      "    \n",
      "                        - either a tensor with matching dimensions to\n",
      "                          corresponding tensor in the inputs' tuple\n",
      "                          or the first dimension is one and the remaining\n",
      "                          dimensions match with the corresponding\n",
      "                          input tensor.\n",
      "                        - or a scalar, corresponding to a tensor in the\n",
      "                          inputs' tuple. This scalar value is broadcasted\n",
      "                          for corresponding input tensor.\n",
      "    \n",
      "                    In the cases when `baselines` is not provided, we internally\n",
      "                    use zero scalar corresponding to each input tensor.\n",
      "    \n",
      "                    Default: None\n",
      "        target (int, tuple, Tensor, or list, optional): Output indices for\n",
      "                    which gradients are computed (for classification cases,\n",
      "                    this is usually the target class).\n",
      "                    If the network returns a scalar value per example,\n",
      "                    no target index is necessary.\n",
      "                    For general 2D outputs, targets can be either:\n",
      "    \n",
      "                    - a single integer or a tensor containing a single\n",
      "                      integer, which is applied to all input examples\n",
      "    \n",
      "                    - a list of integers or a 1D tensor, with length matching\n",
      "                      the number of examples in inputs (dim 0). Each integer\n",
      "                      is applied as the target for the corresponding example.\n",
      "    \n",
      "                    For outputs with > 2 dimensions, targets can be either:\n",
      "    \n",
      "                    - A single tuple, which contains #output_dims - 1\n",
      "                      elements. This target index is applied to all examples.\n",
      "    \n",
      "                    - A list of tuples with length equal to the number of\n",
      "                      examples in inputs (dim 0), and each tuple containing\n",
      "                      #output_dims - 1 elements. Each tuple is applied as the\n",
      "                      target for the corresponding example.\n",
      "    \n",
      "                    Default: None\n",
      "        additional_forward_args (Any, optional): If the forward function\n",
      "                    requires additional arguments other than the inputs for\n",
      "                    which attributions should not be computed, this argument\n",
      "                    can be provided. It must be either a single additional\n",
      "                    argument of a Tensor or arbitrary (non-tuple) type or a\n",
      "                    tuple containing multiple additional arguments including\n",
      "                    tensors or any arbitrary python types. These arguments\n",
      "                    are provided to forward_func in order following the\n",
      "                    arguments in inputs.\n",
      "    \n",
      "                    For a tensor, the first dimension of the tensor must\n",
      "                    correspond to the number of examples. It will be\n",
      "                    repeated for each of `n_steps` along the integrated\n",
      "                    path. For all other types, the given argument is used\n",
      "                    for all forward evaluations.\n",
      "    \n",
      "                    Note that attributions are not computed with respect\n",
      "                    to these arguments.\n",
      "                    Default: None\n",
      "        n_steps (int, optional): The number of steps used by the approximation\n",
      "                    method. Default: 50.\n",
      "        method (str, optional): Method for approximating the integral,\n",
      "                    one of `riemann_right`, `riemann_left`, `riemann_middle`,\n",
      "                    `riemann_trapezoid` or `gausslegendre`.\n",
      "                    Default: `gausslegendre` if no method is provided.\n",
      "        internal_batch_size (int, optional): Divides total #steps * #examples\n",
      "                    data points into chunks of size at most internal_batch_size,\n",
      "                    which are computed (forward / backward passes)\n",
      "                    sequentially. internal_batch_size must be at least equal to\n",
      "                    #examples.\n",
      "    \n",
      "                    For DataParallel models, each batch is split among the\n",
      "                    available devices, so evaluations on each available\n",
      "                    device contain internal_batch_size / num_devices examples.\n",
      "                    If internal_batch_size is None, then all evaluations are\n",
      "                    processed in one batch.\n",
      "                    Default: None\n",
      "        return_convergence_delta (bool, optional): Indicates whether to return\n",
      "                    convergence delta or not. If `return_convergence_delta`\n",
      "                    is set to True convergence delta will be returned in\n",
      "                    a tuple following attributions.\n",
      "                    Default: False\n",
      "        attribute_to_layer_input (bool, optional): Indicates whether to\n",
      "                    compute the attribution with respect to the layer input\n",
      "                    or output. If `attribute_to_layer_input` is set to True\n",
      "                    then the attributions will be computed with respect to\n",
      "                    layer input, otherwise it will be computed with respect\n",
      "                    to layer output.\n",
      "    \n",
      "                    Note that currently it is assumed that either the input\n",
      "                    or the output of internal layer, depending on whether we\n",
      "                    attribute to the input or output, is a single tensor.\n",
      "                    Support for multiple tensors will be added later.\n",
      "                    Default: False\n",
      "    \n",
      "    Returns:\n",
      "        **attributions** or 2-element tuple of **attributions**, **delta**:\n",
      "        - **attributions** (*Tensor* or *tuple[Tensor, ...]*):\n",
      "            Integrated gradients with respect to `layer`'s inputs\n",
      "            or outputs. Attributions will always be the same size and\n",
      "            dimensionality as the input or output of the given layer,\n",
      "            depending on whether we attribute to the inputs or outputs\n",
      "            of the layer which is decided by the input flag\n",
      "            `attribute_to_layer_input`.\n",
      "    \n",
      "            For a single layer, attributions are returned in a tuple if\n",
      "            the layer inputs / outputs contain multiple tensors,\n",
      "            otherwise a single tensor is returned.\n",
      "    \n",
      "            For multiple layers, attributions will always be\n",
      "            returned as a list. Each element in this list will be\n",
      "            equivalent to that of a single layer output, i.e. in the\n",
      "            case that one layer, in the given layers, inputs / outputs\n",
      "            multiple tensors: the corresponding output element will be\n",
      "            a tuple of tensors. The ordering of the outputs will be\n",
      "            the same order as the layers given in the constructor.\n",
      "    \n",
      "        - **delta** (*Tensor*, returned if return_convergence_delta=True):\n",
      "            The difference between the total approximated and true\n",
      "            integrated gradients. This is computed using the property\n",
      "            that the total sum of forward_func(inputs) -\n",
      "            forward_func(baselines) must equal the total sum of the\n",
      "            integrated gradient.\n",
      "            Delta is calculated per example, meaning that the number of\n",
      "            elements in returned delta tensor is equal to the number of\n",
      "            examples in inputs.\n",
      "    \n",
      "    Examples::\n",
      "    \n",
      "        >>> # ImageClassifier takes a single input tensor of images Nx3x32x32,\n",
      "        >>> # and returns an Nx10 tensor of class probabilities.\n",
      "        >>> # It contains an attribute conv1, which is an instance of nn.conv2d,\n",
      "        >>> # and the output of this layer has dimensions Nx12x32x32.\n",
      "        >>> net = ImageClassifier()\n",
      "        >>> lig = LayerIntegratedGradients(net, net.conv1)\n",
      "        >>> input = torch.randn(2, 3, 32, 32, requires_grad=True)\n",
      "        >>> # Computes layer integrated gradients for class 3.\n",
      "        >>> # attribution size matches layer output, Nx12x32x32\n",
      "        >>> attribution = lig.attribute(input, target=3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(LayerIntegratedGradients.attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function register_forward_hook in module torch.nn.modules.module:\n",
      "\n",
      "register_forward_hook(self, hook: Union[Callable[[~T, Tuple[Any, ...], Any], Optional[Any]], Callable[[~T, Tuple[Any, ...], Dict[str, Any], Any], Optional[Any]]], *, prepend: bool = False, with_kwargs: bool = False, always_call: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      "    Registers a forward hook on the module.\n",
      "    \n",
      "    The hook will be called every time after :func:`forward` has computed an output.\n",
      "    \n",
      "    If ``with_kwargs`` is ``False`` or not specified, the input contains only\n",
      "    the positional arguments given to the module. Keyword arguments won't be\n",
      "    passed to the hooks and only to the ``forward``. The hook can modify the\n",
      "    output. It can modify the input inplace but it will not have effect on\n",
      "    forward since this is called after :func:`forward` is called. The hook\n",
      "    should have the following signature::\n",
      "    \n",
      "        hook(module, args, output) -> None or modified output\n",
      "    \n",
      "    If ``with_kwargs`` is ``True``, the forward hook will be passed the\n",
      "    ``kwargs`` given to the forward function and be expected to return the\n",
      "    output possibly modified. The hook should have the following signature::\n",
      "    \n",
      "        hook(module, args, kwargs, output) -> None or modified output\n",
      "    \n",
      "    Args:\n",
      "        hook (Callable): The user defined hook to be registered.\n",
      "        prepend (bool): If ``True``, the provided ``hook`` will be fired\n",
      "            before all existing ``forward`` hooks on this\n",
      "            :class:`torch.nn.modules.Module`. Otherwise, the provided\n",
      "            ``hook`` will be fired after all existing ``forward`` hooks on\n",
      "            this :class:`torch.nn.modules.Module`. Note that global\n",
      "            ``forward`` hooks registered with\n",
      "            :func:`register_module_forward_hook` will fire before all hooks\n",
      "            registered by this method.\n",
      "            Default: ``False``\n",
      "        with_kwargs (bool): If ``True``, the ``hook`` will be passed the\n",
      "            kwargs given to the forward function.\n",
      "            Default: ``False``\n",
      "        always_call (bool): If ``True`` the ``hook`` will be run regardless of\n",
      "            whether an exception is raised while calling the Module.\n",
      "            Default: ``False``\n",
      "    \n",
      "    Returns:\n",
      "        :class:`torch.utils.hooks.RemovableHandle`:\n",
      "            a handle that can be used to remove the added hook by calling\n",
      "            ``handle.remove()``\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nn.Module.register_forward_hook)#, register_backward_hook, or the newer register_full_backward_hook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
