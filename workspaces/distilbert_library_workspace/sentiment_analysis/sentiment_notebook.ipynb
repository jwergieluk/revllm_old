{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import (\n",
    "    DistilBertTokenizer,\n",
    "    DistilBertForSequenceClassification\n",
    ")\n",
    "\n",
    "from revllm_copy.sentiment_analyze_distilbert import sentiment_analysis, qAndA\n",
    "from revllm_copy.sentiment_preprocess import DistilbertSentimentPreprocesser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = DistilbertSentimentPreprocesser(model_name)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "# analyzer = qAndA(model_name, preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"I gotta say it was a good day.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  1045, 10657,  2360,  2009,  2001,  1037,  2204,  2154,  1012,\n",
      "           102]])\n",
      "tensor([[101,   0,   0,   0,   0,   0,   0,   0,   0,   0, 102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "['[CLS]', 'i', 'gotta', 'say', 'it', 'was', 'a', 'good', 'day', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(preprocessor.input_ids)\n",
    "print(preprocessor.baseline_input_ids)\n",
    "print(preprocessor.attention_mask)\n",
    "print(preprocessor.all_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.9981,  4.3832], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(input_ids, attention_mask):\n",
    "    output = model(input_ids, attention_mask=attention_mask)\n",
    "    logits = output.logits\n",
    "\n",
    "    return logits[0]\n",
    "\n",
    "predict(preprocessor.input_ids, preprocessor.attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.6871, -3.8036], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"I gotta say it was a bad day.\"\n",
    "preprocessor(context)\n",
    "predict(preprocessor.input_ids, preprocessor.attention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load tokenizer and model\n",
    "# MODEL_NAME = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained(MODEL_NAME)\n",
    "# model = DistilBertForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# # Function to predict sentiment\n",
    "# def predict_sentiment(text):\n",
    "#     # Tokenize input text and get tensor outputs\n",
    "#     inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "#     logits = outputs.logits\n",
    "#     probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "#     predicted_class = torch.argmax(probs, dim=-1).item()\n",
    "    \n",
    "#     # Convert to positive/negative labels\n",
    "#     labels = ['negative', 'positive']\n",
    "#     return labels[predicted_class]\n",
    "\n",
    "# # Test\n",
    "# text = \"I love this product!\"\n",
    "# result = predict_sentiment(text)\n",
    "# print(f\"The sentiment for '{text}' is: {result}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
