{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('c:\\\\Users\\\\hello\\\\Desktop\\\\llm_bootcamp\\\\revllm_repo')\n",
    "\n",
    "from revllm.preprocess_distilbert import PreprocessMaskedLM\n",
    "from revllm.analyze_distilbert import AnalyzeMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Context: The capital of France, Paris, contains the [MASK] Tower.\n",
      "Unmasked context: The capital of France, Paris, contains the Eiffel Tower.\n",
      "         Context:  The capital of France, Paris, contains the [MASK] Tower.\n",
      "   Actual answer:  Eiffel\n",
      "Predicted answer:  louvre\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "preprocessor = PreprocessMaskedLM(model_name)\n",
    "analyzer = AnalyzeMaskedLM(model_name, preprocessor)\n",
    "\n",
    "context = \"The capital of France, Paris, contains the Eiffel Tower.\"\n",
    "\n",
    "preprocessor(context)\n",
    "analyzer.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 14, 30522])\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(analyzer.logits.shape)\n",
    "print(analyzer.preprocessor.ground_truth_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    DistilBertForMaskedLM,\n",
    "    DistilBertTokenizer\n",
    "    )\n",
    "\n",
    "import os\n",
    "os.chdir('c:\\\\Users\\\\hello\\\\Desktop\\\\llm_bootcamp\\\\revllm_repo')\n",
    "\n",
    "from revllm.preprocess_distilbert import PreprocessMaskedLM\n",
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'distilbert-base-uncased'\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "preprocessor = PreprocessMaskedLM(model_name)\n",
    "model = DistilBertForMaskedLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Context: The capital of France, Paris, contains the [MASK] Tower.\n",
      "Unmasked context: The capital of France, Paris, contains the Eiffel Tower.\n"
     ]
    }
   ],
   "source": [
    "preprocessor(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14, 30522])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 1996, 3007, 1997, 2605, 1010, 3000, 1010, 3397, 1996,  103, 3578,\n",
      "         1012,  102]])\n"
     ]
    }
   ],
   "source": [
    "print(preprocessor.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(preprocessor.input_ids, preprocessor.attention_mask)\n",
    "logits = output.logits\n",
    "probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "predictions = torch.argmax(probs, dim=-1).tolist()\n",
    "mask_prediction_id = predictions[0][preprocessor.mask_index]\n",
    "mask_prediction = tokenizer.convert_ids_to_tokens(mask_prediction_id)\n",
    "# probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "# predicted_classes = torch.argmax(probs, dim=-1).tolist()\n",
    "# # predictions = [preprocessor.labels[p] for p in predicted_classes]\n",
    "\n",
    "# print('        Context: ', preprocessor.context)\n",
    "# print('Predicted Answer: ', predictions[0])\n",
    "# print('   Actual Answer: ', preprocessor.ground_truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'louvre'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    print(sum(probs[0, i,:].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_modified = predictions[0].copy()\n",
    "predictions_modified[0] = 101\n",
    "predictions_modified = predictions_modified[:-1]\n",
    "print(predictions_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.sep_token_id)\n",
    "print(tokenizer.cls_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_tokens_modified = tokenizer.convert_ids_to_tokens(predictions_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction_tokens)\n",
    "print(prediction_tokens_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_tokens_modified = prediction_tokens\n",
    "prediction_tokens_modified[0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_output(list):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_string = tokenizer.convert_tokens_to_string(prediction_tokens)\n",
    "predicted_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "predicted_sentence = re.sub(r'\\s+([?.!,\"])', r'\\1', predicted_string)\n",
    "predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
